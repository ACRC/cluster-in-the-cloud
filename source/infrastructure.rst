Set up the cloud infrastructure
===============================

Getting ready
-------------

The first step is to get a bunch of servers powered on in your cloud.
We do this using a tool called `Terraform <https://www.terraform.io/>`_.

Make sure that Terraform is installed by running the following in the command-line:

.. code-block:: shell-session

   $ terraform version

you should get output like:

.. code-block:: shell-session

   Terraform v0.11.8

We're now ready to start configuring our infrastructure.

Setting the config
------------------

Start by making a new directory which will hold all our configuration.
We will refer to this directory as the *base config directory*.
Change to that directory in your terminal.

Grab the Terraform config from Git using:

.. code-block:: shell-session

   $ git clone https://github.com/ACRC/oci-cluster-terraform.git

Now move into that directory and initialise the Terraform repo:

.. code-block:: shell-session

   $ terraform init

Now, when you check the Terraform version, you should see the OCI provider showing up:

.. code-block:: shell-session

   $ terraform version
   Terraform v0.11.8
   + provider.null v1.0.0
   + provider.oci v3.2.0
   + provider.tls v1.2.0

Rename the example config file ``terraform.tfvars.example`` to ``terraform.tfvars`` and open it in a text editor:

.. code-block:: shell-session

   $ mv terraform.tfvars.example terraform.tfvars
   $ vim terraform.tfvars

Following the instructions at the `Oracle Terraform plugin docs <https://www.terraform.io/docs/providers/oci/index.html#authentication>`_,
set the values of ``tenancy_ocid``, ``user_ocid``, ``private_key_path``, ``fingerprint`` and ``region``.
Make sure that the user account you use for ``user_ocid`` has admin access in your tenancy to create infrastructure.

You will also need to set the compartment OCID of the compartment that you are using.
If you are using the default root compartment, this will be the same as your tenancy OCID.

The next thing to set is an SSH key that you will use to connect to the server once it is built.
See `GitHub's documentation <https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/>`_ on information on how to do this
and then paste the contents of the public key into the ``ssh_public_key`` config variable between the two ``EOF``\ s.

You will want a simple, lightweight VM for the management node so
for this tutorial, we will use ``VM.Standard2.16`` for the management node.

Set the ``ManagementShape`` config variable to the shape you want for the management node::

   ManagementShape = "VM.Standard2.16"

That has defined the types and location of all the nodes we are installing.
We need to tell OCI what OS to install onto the management machine which we do by setting ``ManagementImageOCID``.
To decide what values to put in these, look at `OCI's list of images <https://docs.us-phoenix-1.oraclecloud.com/images/>`_.
We will install the latest version of Oracle Linux onto each::

   ManagementImageOCID = {
     eu-frankfurt-1 = "ocid1.image.oc1.eu-frankfurt-1.aaaaaaaa7qdjjqlvryzxx4i2zs5si53edgmwr2ldn22whv5wv34fc3sdsova"
   }

At this point, we are ready to provision our infrastructure.
Check that there's no immediate errors with

.. code-block:: shell-session

   $ terraform validate

It should return with no errors.
If there are any problems, fix them before continuing.

Next, check that Terraform is ready to run with

.. code-block:: shell-session

   $ terraform plan

which should have, near the end, something like ``Plan: 11 to add, 0 to change, 0 to destroy.``.

We're now ready to go. Run

.. code-block:: shell-session

   $ terraform apply

and, when prompted, tell it that "yes", you do want to apply.

It will take some time but should return without any errors with something green that looks like::

   Apply complete! Resources: 11 added, 0 changed, 0 destroyed.

   Outputs:

   ManagementPublicIP = 130.61.43.69

You are now ready to move on to :doc:`finalising the setup on the cluster <finalise>`.
